{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai import generative_models\n",
    "\n",
    "# Safety config\n",
    "SAFETY_CONFIG = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_UNSPECIFIED: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_api(prompt: str, temperature = 0) -> str:\n",
    "    model = GenerativeModel(\"gemini-pro\", safety_settings=SAFETY_CONFIG)\n",
    "    response = model.generate_content(\n",
    "        prompt\n",
    "    )\n",
    "    output = response.text\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_notes = \"\"\"49 y/o Male with chronic macular rash to face & hair, worse in beard, eyebrows & nares.\n",
    "Itchy, flaky, slightly scaly. Moderate response to OTC steroid cream\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "class Symptom(BaseModel):\n",
    "    symptom: str = Field(description=\"Symptom that a patient is experiencing\")\n",
    "    affected_area: str= Field(description=\"What part of the body the symptom is affecting\")\n",
    "\n",
    "class Medication(BaseModel):\n",
    "    medication: str = Field(description=\"Name of the medication the patient is taking\")\n",
    "    response: str = Field(description=\"How the patient is responding to the medication\")\n",
    "\n",
    "class PatientInfo(BaseModel):\n",
    "    gender: str = Field(description=\"Patient's gender\")\n",
    "    age: int = Field(description=\"Patient's age\")\n",
    "    symptoms: List[Symptom] = Field(description=\"Symptoms that the patient is currently experiencing. Each symptom should be classified into  separate item in the list.\")\n",
    "    current_meds: List[Medication] = Field(description=\"Medications the patient is currently taking and their response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guardrails.validators import ValidRange, ValidChoices\n",
    "\n",
    "class Symptom(BaseModel):\n",
    "    symptom: str = Field(description=\"Symptom that a patient is experiencing\")\n",
    "    affected_area: str= Field(\n",
    "        description=\"What part of the body the symptom is affecting\",\n",
    "        #(2)!\n",
    "        validators=[ValidChoices(choices=['head', 'neck', 'chest'], on_fail='reask')]\n",
    "    ) \n",
    "\n",
    "class Medication(BaseModel):\n",
    "    medication: str = Field(description=\"Name of the medication the patient is taking\")\n",
    "    response: str = Field(description=\"How the patient is responding to the medication\")\n",
    "\n",
    "class PatientInfo(BaseModel):\n",
    "    gender: str = Field(description=\"Patient's gender\")\n",
    "    age: int = Field(\n",
    "        description=\"Patient's age\",\n",
    "        #(1)!\n",
    "        validators=[ValidRange(min=0, max=100)]\n",
    "    )\n",
    "    symptoms: List[Symptom] = Field(description=\"Symptoms that the patient is currently experiencing. Each symptom should be classified into  separate item in the list.\")\n",
    "    current_meds: List[Medication] = Field(description=\"Medications the patient is currently taking and their response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Given the following doctor's notes about a patient,\n",
    "please extract a dictionary that contains the patient's information.  <!-- (1)! -->\n",
    "\n",
    "${doctors_notes}  <!-- (2)! -->\n",
    "\n",
    "${gr.complete_json_suffix_v2}  <!-- (3)! -->\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from guardrails.validators import ValidRange, ValidChoices\n",
    "\n",
    "prompt = \"\"\"\n",
    "Given the following doctor's notes about a patient, please extract a dictionary that contains the patient's information.\n",
    "\n",
    "${doctors_notes}\n",
    "\n",
    "${gr.complete_json_suffix_v2}\n",
    "\"\"\"\n",
    "\n",
    "class Symptom(BaseModel):\n",
    "    symptom: str = Field(description=\"Symptom that a patient is experiencing\")\n",
    "    affected_area: str = Field(description=\"What part of the body the symptom is affecting\", validators=[ValidChoices(choices=['head', 'neck', 'chest'], on_fail=\"reask\")])\n",
    "\n",
    "class Medication(BaseModel):\n",
    "    medication: str = Field(description=\"Name of the medication the patient is taking\")\n",
    "    response: str = Field(description=\"How the patient is responding to the medication\")\n",
    "\n",
    "\n",
    "class PatientInfo(BaseModel):\n",
    "    gender: str = Field(description=\"Patient's gender\")\n",
    "    age: int = Field(validators=[ValidRange(min=0, max=100, on_fail=\"fix\")])\n",
    "    symptoms: List[Symptom] = Field(description=\"Symptoms that the patient is currently experiencing. Each symptom should be classified into a separate item in the list.\")\n",
    "    current_meds: List[Medication] = Field(description=\"Medications the patient is currently taking and their response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "\n",
    "# From pydantic:\n",
    "guard = gd.Guard.from_pydantic(output_class=PatientInfo, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes the prompt as a string and returns the LLM output as string\n",
    "def my_llm_api(prompt: str, **kwargs) -> str:\n",
    "    \"\"\"Custom LLM API wrapper.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to be passed to the LLM API\n",
    "        **kwargs: Any additional arguments to be passed to the LLM API\n",
    "\n",
    "    Returns:\n",
    "        str: The output of the LLM API\n",
    "    \"\"\"\n",
    "\n",
    "    output = gemini_api(prompt)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searcharray import SearchArray\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doug</td>\n",
       "      <td>Hi this is Doug, I'd like to complain about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doug</td>\n",
       "      <td>Doug, this is Tom, support for Earth's Climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom</td>\n",
       "      <td>Tom, can I speak to your manager?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>Hi, this is Sue, Tom's boss. What can I do for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doug</td>\n",
       "      <td>I'd like to complain about the ski conditions ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                                msg\n",
       "0  Doug  Hi this is Doug, I'd like to complain about th...\n",
       "1  Doug  Doug, this is Tom, support for Earth's Climate...\n",
       "2   Tom                  Tom, can I speak to your manager?\n",
       "3   Sue  Hi, this is Sue, Tom's boss. What can I do for...\n",
       "4  Doug  I'd like to complain about the ski conditions ..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_transcript = [\n",
    "  \"Hi this is Doug, I'd like to complain about the weather\",\n",
    "  \"Doug, this is Tom, support for Earth's Climate, how can we help?\",\n",
    "  \"Tom, can I speak to your manager?\",\n",
    "  \"Hi, this is Sue, Tom's boss. What can I do for you?\",\n",
    "  \"I'd like to complain about the ski conditions in West Virginia\"\n",
    "]\n",
    "\n",
    "msgs = pd.DataFrame({\"name\": [\"Doug\", \"Doug\", \"Tom\", \"Sue\", \"Doug\"],\n",
    "                     \"msg\": chat_transcript})\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doug</td>\n",
       "      <td>Hi this is Doug, I'd like to complain about th...</td>\n",
       "      <td>Terms({'complain', 'weather', 'this', 'about',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doug</td>\n",
       "      <td>Doug, this is Tom, support for Earth's Climate...</td>\n",
       "      <td>Terms({'help?', 'this', 'can', 'we', 'Tom,', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom</td>\n",
       "      <td>Tom, can I speak to your manager?</td>\n",
       "      <td>Terms({'can', 'to', 'Tom,', 'manager?', 'I', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>Hi, this is Sue, Tom's boss. What can I do for...</td>\n",
       "      <td>Terms({'this', 'can', 'boss.', 'do', 'Hi,', \"T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doug</td>\n",
       "      <td>I'd like to complain about the ski conditions ...</td>\n",
       "      <td>Terms({'complain', 'to', 'Virginia', 'the', 'W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                                msg  \\\n",
       "0  Doug  Hi this is Doug, I'd like to complain about th...   \n",
       "1  Doug  Doug, this is Tom, support for Earth's Climate...   \n",
       "2   Tom                  Tom, can I speak to your manager?   \n",
       "3   Sue  Hi, this is Sue, Tom's boss. What can I do for...   \n",
       "4  Doug  I'd like to complain about the ski conditions ...   \n",
       "\n",
       "                                       msg_tokenized  \n",
       "0  Terms({'complain', 'weather', 'this', 'about',...  \n",
       "1  Terms({'help?', 'this', 'can', 'we', 'Tom,', '...  \n",
       "2  Terms({'can', 'to', 'Tom,', 'manager?', 'I', '...  \n",
       "3  Terms({'this', 'can', 'boss.', 'do', 'Hi,', \"T...  \n",
       "4  Terms({'complain', 'to', 'Virginia', 'the', 'W...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs['msg_tokenized'] = SearchArray.index(msgs['msg'])\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_tokenized</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doug</td>\n",
       "      <td>Hi this is Doug, I'd like to complain about th...</td>\n",
       "      <td>Terms({'complain', 'weather', 'this', 'about',...</td>\n",
       "      <td>0.620554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doug</td>\n",
       "      <td>Doug, this is Tom, support for Earth's Climate...</td>\n",
       "      <td>Terms({'help?', 'this', 'can', 'we', 'Tom,', '...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom</td>\n",
       "      <td>Tom, can I speak to your manager?</td>\n",
       "      <td>Terms({'can', 'to', 'Tom,', 'manager?', 'I', '...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>Hi, this is Sue, Tom's boss. What can I do for...</td>\n",
       "      <td>Terms({'this', 'can', 'boss.', 'do', 'Hi,', \"T...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doug</td>\n",
       "      <td>I'd like to complain about the ski conditions ...</td>\n",
       "      <td>Terms({'complain', 'to', 'Virginia', 'the', 'W...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                                msg  \\\n",
       "0  Doug  Hi this is Doug, I'd like to complain about th...   \n",
       "1  Doug  Doug, this is Tom, support for Earth's Climate...   \n",
       "2   Tom                  Tom, can I speak to your manager?   \n",
       "3   Sue  Hi, this is Sue, Tom's boss. What can I do for...   \n",
       "4  Doug  I'd like to complain about the ski conditions ...   \n",
       "\n",
       "                                       msg_tokenized     score  \n",
       "0  Terms({'complain', 'weather', 'this', 'about',...  0.620554  \n",
       "1  Terms({'help?', 'this', 'can', 'we', 'Tom,', '...  0.000000  \n",
       "2  Terms({'can', 'to', 'Tom,', 'manager?', 'I', '...  0.000000  \n",
       "3  Terms({'this', 'can', 'boss.', 'do', 'Hi,', \"T...  0.000000  \n",
       "4  Terms({'complain', 'to', 'Virginia', 'the', 'W...  0.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs['score'] = msgs['msg_tokenized'].array.score(\"weather\")\n",
    "msgs.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorengine import VectorEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 0\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n"
     ]
    }
   ],
   "source": [
    "ec_store = VectorEngine(\"/Users/arjun/Documents/github/research-agent/docs/sop-docs/euroclear\", collection_name=\"ec_sop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>content_vector</th>\n",
       "      <th>keywords</th>\n",
       "      <th>vector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>external-settlement</td>\n",
       "      <td>## External settlement\\n19/09/2022\\n\\n### What...</td>\n",
       "      <td>[-0.014352154918015003, -0.008465911261737347,...</td>\n",
       "      <td>- external-settlement\\n- Euroclear client\\n- c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>transaction-lifecycle</td>\n",
       "      <td>## What is the lifecycle of transactions?\\n\\nT...</td>\n",
       "      <td>[-0.018114324659109116, -0.008524619974195957,...</td>\n",
       "      <td>- transaction-lifecycle\\n- Input\\n- Validation...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>bridge-settlement</td>\n",
       "      <td>## Bridge settlement\\n\\n### What is a Bridge s...</td>\n",
       "      <td>[-0.013597985729575157, 0.005742959678173065, ...</td>\n",
       "      <td>- Bridge settlement\\n- Euroclear Bank\\n- Clear...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>status-reporting</td>\n",
       "      <td>## Unmatched, unsettled, alleged reporting\\n21...</td>\n",
       "      <td>[-0.02043256163597107, -0.014711612835526466, ...</td>\n",
       "      <td>- status-reporting\\n- unmatched\\n- unsettled\\n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>internal-settlement</td>\n",
       "      <td>## What is an internal settlement transaction?...</td>\n",
       "      <td>[-0.03241455554962158, 0.045177578926086426, -...</td>\n",
       "      <td>internal-settlement\\nEuroclear Bank\\npayment c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>australia-market</td>\n",
       "      <td>## Australia - Market basics\\n31/01/2024\\n\\n##...</td>\n",
       "      <td>[-0.005053657107055187, -0.01641596108675003, ...</td>\n",
       "      <td>- Australia\\n- Market basics\\n- Equities servi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>united-kingdon-market</td>\n",
       "      <td>## United Kingdom - Market basics\\n04/11/2021\\...</td>\n",
       "      <td>[-0.007458867039531469, -0.010519517585635185,...</td>\n",
       "      <td>- United Kingdom\\n- Market basics\\n- Direct li...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>china-market</td>\n",
       "      <td>## China - Market basics\\n10/11/2023\\n\\n### Wh...</td>\n",
       "      <td>[0.00048036323278211057, -0.017352476716041565...</td>\n",
       "      <td>- china-market\\n- Direct account in SHCH\\n- In...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>hong-kong-market</td>\n",
       "      <td>## Hong Kong - Market basics\\n17/11/2023\\n\\n##...</td>\n",
       "      <td>[-0.0014984990702942014, -0.02539912983775139,...</td>\n",
       "      <td>- Hong Kong\\n- Market basics\\n- Safekeeping\\n-...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>/Users/arjun/Documents/github/research-agent/d...</td>\n",
       "      <td>united-states-market</td>\n",
       "      <td>## United States - Market basics\\n\\n### Safeke...</td>\n",
       "      <td>[0.004938406404107809, -0.007323066238313913, ...</td>\n",
       "      <td>- United States\\n- Market basics\\n- Safekeepin...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          file_path  \\\n",
       "0   1  /Users/arjun/Documents/github/research-agent/d...   \n",
       "1   2  /Users/arjun/Documents/github/research-agent/d...   \n",
       "2   3  /Users/arjun/Documents/github/research-agent/d...   \n",
       "3   4  /Users/arjun/Documents/github/research-agent/d...   \n",
       "4   5  /Users/arjun/Documents/github/research-agent/d...   \n",
       "5   6  /Users/arjun/Documents/github/research-agent/d...   \n",
       "6   7  /Users/arjun/Documents/github/research-agent/d...   \n",
       "7   8  /Users/arjun/Documents/github/research-agent/d...   \n",
       "8   9  /Users/arjun/Documents/github/research-agent/d...   \n",
       "9  10  /Users/arjun/Documents/github/research-agent/d...   \n",
       "\n",
       "                   title                                               text  \\\n",
       "0    external-settlement  ## External settlement\\n19/09/2022\\n\\n### What...   \n",
       "1  transaction-lifecycle  ## What is the lifecycle of transactions?\\n\\nT...   \n",
       "2      bridge-settlement  ## Bridge settlement\\n\\n### What is a Bridge s...   \n",
       "3       status-reporting  ## Unmatched, unsettled, alleged reporting\\n21...   \n",
       "4    internal-settlement  ## What is an internal settlement transaction?...   \n",
       "5       australia-market  ## Australia - Market basics\\n31/01/2024\\n\\n##...   \n",
       "6  united-kingdon-market  ## United Kingdom - Market basics\\n04/11/2021\\...   \n",
       "7           china-market  ## China - Market basics\\n10/11/2023\\n\\n### Wh...   \n",
       "8       hong-kong-market  ## Hong Kong - Market basics\\n17/11/2023\\n\\n##...   \n",
       "9   united-states-market  ## United States - Market basics\\n\\n### Safeke...   \n",
       "\n",
       "                                      content_vector  \\\n",
       "0  [-0.014352154918015003, -0.008465911261737347,...   \n",
       "1  [-0.018114324659109116, -0.008524619974195957,...   \n",
       "2  [-0.013597985729575157, 0.005742959678173065, ...   \n",
       "3  [-0.02043256163597107, -0.014711612835526466, ...   \n",
       "4  [-0.03241455554962158, 0.045177578926086426, -...   \n",
       "5  [-0.005053657107055187, -0.01641596108675003, ...   \n",
       "6  [-0.007458867039531469, -0.010519517585635185,...   \n",
       "7  [0.00048036323278211057, -0.017352476716041565...   \n",
       "8  [-0.0014984990702942014, -0.02539912983775139,...   \n",
       "9  [0.004938406404107809, -0.007323066238313913, ...   \n",
       "\n",
       "                                            keywords vector_id  \n",
       "0  - external-settlement\\n- Euroclear client\\n- c...         0  \n",
       "1  - transaction-lifecycle\\n- Input\\n- Validation...         1  \n",
       "2  - Bridge settlement\\n- Euroclear Bank\\n- Clear...         2  \n",
       "3  - status-reporting\\n- unmatched\\n- unsettled\\n...         3  \n",
       "4  internal-settlement\\nEuroclear Bank\\npayment c...         4  \n",
       "5  - Australia\\n- Market basics\\n- Equities servi...         5  \n",
       "6  - United Kingdom\\n- Market basics\\n- Direct li...         6  \n",
       "7  - china-market\\n- Direct account in SHCH\\n- In...         7  \n",
       "8  - Hong Kong\\n- Market basics\\n- Safekeeping\\n-...         8  \n",
       "9  - United States\\n- Market basics\\n- Safekeepin...         9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_store.doc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['clearstream']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/github/research-agent/llmnv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fusion \u001b[38;5;241m=\u001b[39m \u001b[43mec_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank_fusion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclearstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/research-agent/gemini-agent/vectorengine.py:207\u001b[0m, in \u001b[0;36mVectorEngine.rank_fusion\u001b[0;34m(self, query, dense_k, fusion_k)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrank_fusion\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, dense_k, fusion_k) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    203\u001b[0m     dense_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_df(\n\u001b[1;32m    204\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[1;32m    205\u001b[0m         max_results\u001b[38;5;241m=\u001b[39mdense_k,\n\u001b[1;32m    206\u001b[0m         )\n\u001b[0;32m--> 207\u001b[0m     bm25_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm25_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdense_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     default_dense_rank \u001b[38;5;241m=\u001b[39m dense_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    209\u001b[0m     default_bm25_rank \u001b[38;5;241m=\u001b[39m bm25_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/github/research-agent/gemini-agent/vectorengine.py:194\u001b[0m, in \u001b[0;36mVectorEngine.bm25_rank\u001b[0;34m(self, query, search_df, k)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(split_words)\n\u001b[1;32m    193\u001b[0m lower_split \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m split_words]\n\u001b[0;32m--> 194\u001b[0m search_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_content\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msearch_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(clean_string)\n\u001b[1;32m    195\u001b[0m search_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25_tokenized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m SearchArray\u001b[38;5;241m.\u001b[39mindex(search_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_content\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    196\u001b[0m search_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m search_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25_tokenized\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mscore(lower_split)  \u001b[38;5;66;03m# need to change this up a but - for each word and then add?\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/research-agent/llmnv/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/github/research-agent/llmnv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "fusion = ec_store.rank_fusion(\"clearstream\", 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ec_store.search_df(\"clearstream\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.660603</td>\n",
       "      <td>united-states-market</td>\n",
       "      <td>## United States - Market basics\\n\\n### Safeke...</td>\n",
       "      <td>- United States\\n- Market basics\\n- Safekeepin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.649718</td>\n",
       "      <td>status-reporting</td>\n",
       "      <td>## Unmatched, unsettled, alleged reporting\\n21...</td>\n",
       "      <td>- status-reporting\\n- unmatched\\n- unsettled\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.639366</td>\n",
       "      <td>bridge-settlement</td>\n",
       "      <td>## Bridge settlement\\n\\n### What is a Bridge s...</td>\n",
       "      <td>- Bridge settlement\\n- Euroclear Bank\\n- Clear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.615352</td>\n",
       "      <td>external-settlement</td>\n",
       "      <td>## External settlement\\n19/09/2022\\n\\n### What...</td>\n",
       "      <td>- external-settlement\\n- Euroclear client\\n- c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id     score                 title  \\\n",
       "9  3  0.660603  united-states-market   \n",
       "3  9  0.649718      status-reporting   \n",
       "2  0  0.639366     bridge-settlement   \n",
       "0  2  0.615352   external-settlement   \n",
       "\n",
       "                                             content  \\\n",
       "9  ## United States - Market basics\\n\\n### Safeke...   \n",
       "3  ## Unmatched, unsettled, alleged reporting\\n21...   \n",
       "2  ## Bridge settlement\\n\\n### What is a Bridge s...   \n",
       "0  ## External settlement\\n19/09/2022\\n\\n### What...   \n",
       "\n",
       "                                            keywords  \n",
       "9  - United States\\n- Market basics\\n- Safekeepin...  \n",
       "3  - status-reporting\\n- unmatched\\n- unsettled\\n...  \n",
       "2  - Bridge settlement\\n- Euroclear Bank\\n- Clear...  \n",
       "0  - external-settlement\\n- Euroclear client\\n- c...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['clearstream']\n"
     ]
    }
   ],
   "source": [
    "bmout = ec_store.bm25_rank(\"clearstream\", out, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>keywords</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>bm25_tokenized</th>\n",
       "      <th>bm25_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.639366</td>\n",
       "      <td>bridge-settlement</td>\n",
       "      <td>## Bridge settlement\\n\\n### What is a Bridge s...</td>\n",
       "      <td>- Bridge settlement\\n- Euroclear Bank\\n- Clear...</td>\n",
       "      <td>bridge settlement is bridge settlement transac...</td>\n",
       "      <td>Terms({'armoured', 'luxembourg', 'cad', 'mxn',...</td>\n",
       "      <td>0.927519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.660603</td>\n",
       "      <td>united-states-market</td>\n",
       "      <td>## United States - Market basics\\n\\n### Safeke...</td>\n",
       "      <td>- United States\\n- Market basics\\n- Safekeepin...</td>\n",
       "      <td>united states market basics safekeeping govern...</td>\n",
       "      <td>Terms({\"'naked'\", 'related', 'transparency', '...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.649718</td>\n",
       "      <td>status-reporting</td>\n",
       "      <td>## Unmatched, unsettled, alleged reporting\\n21...</td>\n",
       "      <td>- status-reporting\\n- unmatched\\n- unsettled\\n...</td>\n",
       "      <td>unmatched unsettled alleged reporting 21 05 20...</td>\n",
       "      <td>Terms({'matched', 'circumstances', 'buyer', 'p...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.615352</td>\n",
       "      <td>external-settlement</td>\n",
       "      <td>## External settlement\\n19/09/2022\\n\\n### What...</td>\n",
       "      <td>- external-settlement\\n- Euroclear client\\n- c...</td>\n",
       "      <td>external settlement 19 09 2022 is external set...</td>\n",
       "      <td>Terms({'managing', 'search', 'amsterdam', 'cle...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id     score                 title  \\\n",
       "2  0  0.639366     bridge-settlement   \n",
       "9  3  0.660603  united-states-market   \n",
       "3  9  0.649718      status-reporting   \n",
       "0  2  0.615352   external-settlement   \n",
       "\n",
       "                                             content  \\\n",
       "2  ## Bridge settlement\\n\\n### What is a Bridge s...   \n",
       "9  ## United States - Market basics\\n\\n### Safeke...   \n",
       "3  ## Unmatched, unsettled, alleged reporting\\n21...   \n",
       "0  ## External settlement\\n19/09/2022\\n\\n### What...   \n",
       "\n",
       "                                            keywords  \\\n",
       "2  - Bridge settlement\\n- Euroclear Bank\\n- Clear...   \n",
       "9  - United States\\n- Market basics\\n- Safekeepin...   \n",
       "3  - status-reporting\\n- unmatched\\n- unsettled\\n...   \n",
       "0  - external-settlement\\n- Euroclear client\\n- c...   \n",
       "\n",
       "                                       clean_content  \\\n",
       "2  bridge settlement is bridge settlement transac...   \n",
       "9  united states market basics safekeeping govern...   \n",
       "3  unmatched unsettled alleged reporting 21 05 20...   \n",
       "0  external settlement 19 09 2022 is external set...   \n",
       "\n",
       "                                      bm25_tokenized  bm25_score  \n",
       "2  Terms({'armoured', 'luxembourg', 'cad', 'mxn',...    0.927519  \n",
       "9  Terms({\"'naked'\", 'related', 'transparency', '...    0.000000  \n",
       "3  Terms({'matched', 'circumstances', 'buyer', 'p...    0.000000  \n",
       "0  Terms({'managing', 'search', 'amsterdam', 'cle...    0.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do bm25 first then vector? nope. maybe just bm25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
