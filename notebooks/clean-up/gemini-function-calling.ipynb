{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful links:\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/get-token-count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **simple response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")\n",
    "\n",
    "def generate_function_call(prompt: str) -> str:\n",
    "    # Load the Vertex AI Gemini API to use function calling\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "    # Specify a function declaration and parameters for an API request\n",
    "    get_current_weather_func = FunctionDeclaration(\n",
    "        name=\"get_current_weather\",\n",
    "        description=\"Get the current weather in a given location\",\n",
    "        # Function parameters are specified in OpenAPI JSON schema format\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"Location\"}},\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Define a tool that includes the above get_current_weather_func\n",
    "    weather_tool = Tool(\n",
    "        function_declarations=[get_current_weather_func],\n",
    "    )\n",
    "\n",
    "    # Prompt to ask the model about weather, which will invoke the Tool\n",
    "    prompt = prompt\n",
    "\n",
    "    # Instruct the model to generate content using the Tool that you just created:\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config={\"temperature\": 0},\n",
    "        tools=[weather_tool],\n",
    "    )\n",
    "\n",
    "    # Transform the structured data into a Python dictionary\n",
    "    params = {}\n",
    "    for key, value in response.candidates[0].content.parts[0].function_call.args.items():\n",
    "        params[key] = value\n",
    "    params\n",
    "\n",
    "    # This is where you would make an API request to get the location of the store closest to the user.\n",
    "    # Here we'll use synthetic data to simulate a response payload from an external API.\n",
    "    api_response = \"\"\"{ \"location\": \"Boston, MA\", \"temperature\": 38, \"description\": \"Partly Cloudy\",\n",
    "                  \"icon\": \"partly-cloudy\", \"humidity\": 65, \"wind\": { \"speed\": 10, \"direction\": \"NW\" } }\"\"\"\n",
    "\n",
    "    # Return the API response to Gemini so it can generate a model response or request another function call\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "        Content(role=\"user\", parts=[\n",
    "            Part.from_text(prompt),\n",
    "        ]),\n",
    "        Content(role=\"function\", parts=[\n",
    "            Part.from_dict({\n",
    "                \"function_call\": {\n",
    "                    \"name\": \"get_current_weather\",\n",
    "                }\n",
    "            })\n",
    "        ]),\n",
    "        Content(role=\"function\", parts=[\n",
    "            Part.from_function_response(\n",
    "                name=\"get_current_weather\",\n",
    "                response={\n",
    "                    \"content\": api_response,\n",
    "                }\n",
    "            )\n",
    "        ]),\n",
    "        ],\n",
    "        tools=[weather_tool],\n",
    "    )\n",
    "\n",
    "    answer = response.candidates[0].content.parts[0].text\n",
    "\n",
    "    return (response, params, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **multi-turn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_response\n",
      " candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"For which location would you like to know the weather?\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 39\n",
      "  candidates_token_count: 11\n",
      "  total_token_count: 50\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vertexai import generative_models\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "get_current_weather_func = generative_models.FunctionDeclaration(\n",
    "  name=\"get_current_weather\",\n",
    "  description=\"Get the current weather in a given location\",\n",
    "  parameters={\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "          \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\n",
    "                  \"celsius\",\n",
    "                  \"fahrenheit\",\n",
    "              ]\n",
    "          }\n",
    "      },\n",
    "      \"required\": [\n",
    "          \"location\"\n",
    "      ]\n",
    "  },\n",
    ")\n",
    "\n",
    "weather_tool = generative_models.Tool(\n",
    "  function_declarations=[get_current_weather_func],\n",
    ")\n",
    "\n",
    "function_calling_chat = model.start_chat()\n",
    "model_response = function_calling_chat.send_message(\"What is the weather like?\", tools=[weather_tool])\n",
    "print(\"model_response\\n\", model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_response\n",
      " candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      function_call {\n",
      "        name: \"get_current_weather\"\n",
      "        args {\n",
      "          fields {\n",
      "            key: \"location\"\n",
      "            value {\n",
      "              string_value: \"boston, ma\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 54\n",
      "  candidates_token_count: 9\n",
      "  total_token_count: 63\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_response = function_calling_chat.send_message(\"in boston please?\", tools=[weather_tool])\n",
    "print(\"model_response\\n\", model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_response\n",
      " candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"The weather in boston, ma is super nice.\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 74\n",
      "  candidates_token_count: 10\n",
      "  total_token_count: 84\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_response = function_calling_chat.send_message(\n",
    "  Part.from_function_response(\n",
    "      name=\"get_current_weather\",\n",
    "      response={\n",
    "          \"content\": {\"weather_there\": \"super nice\"},\n",
    "      }\n",
    "  ),\n",
    "  tools=[weather_tool]\n",
    ")\n",
    "print(\"model_response\\n\", model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[role: \"user\"\n",
       " parts {\n",
       "   text: \"What is the weather like?\"\n",
       " },\n",
       " role: \"model\"\n",
       " parts {\n",
       "   text: \"For which location would you like to know the weather?\"\n",
       " },\n",
       " role: \"user\"\n",
       " parts {\n",
       "   text: \"in boston please?\"\n",
       " },\n",
       " role: \"model\"\n",
       " parts {\n",
       "   function_call {\n",
       "     name: \"get_current_weather\"\n",
       "     args {\n",
       "       fields {\n",
       "         key: \"location\"\n",
       "         value {\n",
       "           string_value: \"boston, ma\"\n",
       "         }\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " },\n",
       " role: \"user\"\n",
       " parts {\n",
       "   function_response {\n",
       "     name: \"get_current_weather\"\n",
       "     response {\n",
       "       fields {\n",
       "         key: \"content\"\n",
       "         value {\n",
       "           struct_value {\n",
       "             fields {\n",
       "               key: \"weather_there\"\n",
       "               value {\n",
       "                 string_value: \"super nice\"\n",
       "               }\n",
       "             }\n",
       "           }\n",
       "         }\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " },\n",
       " role: \"model\"\n",
       " parts {\n",
       "   text: \"The weather there is super nice.\"\n",
       " }]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_calling_chat.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
